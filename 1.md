# 并行计算技术简介
* 提高计算机性能有哪些基本技术手段 
```
1. 提高处理器字长
2. 提高芯片集成度 
3. 流水线等微体系结构技术 
4. 提高处理器频率
```
* 迫切需要发展并行计算技术的主要原因 
```
1. 单核处理器性能提升接近极限
2. 单处理器向多核/众核并行计算发展成为必然趋势 
3. 应用领域计算规模和复杂度大幅提高
```
* 并行计算技术的分类
```
1. 按数据和指令处理结构：弗林(Flynn)分类：
    * SISD：单指令单数据流 
    * SIMD：单指令多数据流
    * MISD：多指令单数据流 
    * MIMD：多指令多数据流(最常用)
2. 按并行类型 
    * 线程级并行(数据级并行：一个大的数据块划分为小块，分别由不同的处理器/线程处理
，任务级并行：一个大的计算任务划分为子任务分别由不同的处理器/线程来处理)
3. 按存储访问构架 
    * 共享内存：所有处理器通过总线共享内存
    * 各个处理器有本地存储器，同时再共享一个全局的存储器
    * 各个处理器使用本地独立的存储器 
4. 按系统类型 
    * 多核/众核并行计算系统MC
    * 对称多处理系统SMP：多个相同类型处理器通过总线连接并共享存储器 
    * 大规模并行处理MPP：专用内联网连接一组处理器形成的一个计算系统 
    * 集群：网络连接的一组普通商用计算机构成的计算系统 
    * 网格：用网络连接远距离分布的一组异构计算机构成的计算系统
5. 按计算特征 
    * 数据密集型并行计算：数据量极大、但计算相对简单的并行处理 
    * 计算密集型并行计算：数据量相对不是很大、但计算较为复杂的并行处理 
    * 数据密集与计算密集混合型并行计算：兼具数据密集型和计算密集型特征的并行计算
6. 按并行程序设计模型/方法
    * 共享内存变量:Pthread,OpenMP:共享内存式多处理并行编程接口 
    * 消息传递方式:MPI：消息传递并行编程接口标准 
    * MapReduce方式 
```
* 并行计算的主要技术问题 
```
1. 多核/多处理器网络互连结构技术 
2. 存储访问体系结构
3. 分布式数据与文件管理
4. 并行计算任务的分解与算法设计 
5. 并行程序设计模型和方法 
6. 数据同步访问和通信控制
7. 可靠性设计与容错技术
8. 并行计算软件框架平台 
9. 系统性能评估和程序并行度评估 
```
* MPI并行程序设计 
   * MPI功能:在处理器间以消息传递方式进行数据通信和同步，以库函数形式为程序员提供了一组易于使用的编程接口;用常规语言编程方式，所有节点运行同一个程序，但处理不同的数据 
   * MPI特点:提供可靠的、面向消息的通信；在高性能科学计算领域广泛使用，适合于处理计算密集型的科学计算；独立于语言的编程规范，可移植性好
   * MPI程序结构:
```
#include <mpi.h>
main(int argc, char **argv) { 
    int numtasks, rank;
    MPI_Init(&argc, &argv);
    ……
    并行计算程序体 
    ……
    MPI_Finalize(); exit(0);
}
```
   * MPI基本编程接口 
   ```
   MPI_Init (argc, argv) : 初始化MPI，开始MPI并行计算程序体 
   MPI_Finalize : 终止MPI并行计算 
   MPI_Comm_Size(comm, (int*)size) : 确定指定范围内处理器/进程数目  MPI_Comm_Rank(comm, (int*)rank) : 确定一个处理器/进程的标识号 
   MPI_Send (buf, count, datatype, dest, tag, comm) : 发送一个消息 
   MPI_Recv (buf, count, datatype, source, tag, comm, status) : 接受消息 size: 进程数，rank：指定进程的ID comm：指定一个通信组(communicator) Dest：目标进程号，source：源进程标识号，tag：消息标签
   ```
   * MPI编程实例 
```
   #include <mpi.h> 
   #include <stdio.h> 
   main(int argc, char **argv) 
   { 
       int num, rk; 
       MPI_Init(&argc, &argv); 
       MPI_Comm_size(MPI_COMM_WORLD, & num); 
       MPI_Comm_rank(MPI_COMM_WORLD, &rk); 
       printf("Hello world from Process %d of %d\n",rk,num); 
       MPI_Finalize(); 
    } 
    输出:
    Hello world from Process 0 of 5 
    Hello world from Process 1 of 5 
    Hello world from Process 2 of 5 
    Hello world from Process 3 of 5 
    Hello world from Process 4 of 5
```
```
#include <stdio.h>      
#include <mpi.h> 
int main(intargc, char** argv) 
{ 
    in tmyid,numprocs, source; 
    MPI_Statusstatus;   
    char message[100]; 
    MPI_Init(&argc, &argv); 
    MPI_Comm_rank(MPI_COMM_WORLD, &myid); 
    MPI_Comm_size(MPI_COMM_WORLD,&numprocs); 
    if (myid ！= 0)  /* 其他进程，向0进程发送HelloWorld信息*/ 
    {    
        strcpy(message, “Hello World!”); 
        MPI_Send(message,strlen(message)+1, MPI_CHAR, 0,99,MPI_COMM_WORLD); 
    } 
    else  /* 0进程负责从其他进程接受信息并输出*/ 
    {   
        for (source = 1; source < numprocs; source++) 
        {    
            MPI_Recv(message, 100, MPI_CHAR, source, 99,MPI_COMM_WORLD, &status); 
            printf("I am process %d. I recv string '%s' from process %d.\n", myid,message,source); 
        } 
    } 
        MPI_Finalize(); 
} I 
```
* MPI的特点 
1. 灵活性好，适合于各种计算密集型的并行计算任务 
2. 独立于语言的编程规范，可移植性好
3. 有很多开放机构或厂商实现并支持 
* MPI的不足 
1. 无良好的数据和任务划分支持
2. 缺少分布文件系统支持分布数据存储管理 
3. 通信开销大，当计算问题复杂、节点数量很大时，难以处理，性能大幅下降 
4. 无节点失效恢复机制，一旦有节点失效，可能导致计算过程无效 
5. 缺少良好的构架支撑，程序员需要考虑以上所有细节问题，程序设计较为复杂

* 为什么需要大规模数据并行处理
1. 数据处理能力大幅落后于数据增长速度 
2. 大数据将带来巨大的技术和商业机遇
3. 大数据隐含着更准确的事实 

* 大数据的特点 
1. Volume: 大容量,TB-ZB 
2. Variety:  多样性 
3. Velocity: 时效性 
4. Veracity: 准确性 
5. Complexity:复杂性

* 大数据研究的挑战 
1. 数据规模导致难以应对的存储量 
2. 数据规模导致传统算法失效 
3. 大数据复杂的数据关联性导致高复杂度的计算 

* 大数据研究的基本途径 
1. 寻找新算法降低计算复杂度 
2. 降低大数据尺度，寻找数据尺度无关算法 
3. 大数据并行化处理

* 什么是MapReduce
1. 基于集群的高性能并行计算平台
2. 并行程序开发与运行框架
3. 并行程序设计模型与方法

* 为什么MapReduce如此重要
1. 高效的大规模数据处理方法 
2. 改变了大规模尺度上组织计算的方式
3. 第一个不同于冯诺依曼结构的、基于集群而非单机的计算方式的重大突破 
4. 目前为止最为成功的基于大规模计算资源的并行计算抽象方法