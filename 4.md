# MapReduce算法设计 
* MapReduce可解决哪些算法问题
1. 基本算法: 各种全局数据相关性小、能适当划分数据的计算任务
    * 分布式排序 
    * 分布式GREP(文本匹配查找) 
    * 关系代数操作 
    * 矩阵向量相乘、矩阵相乘 
    * 词频统计(word count)，词频重要性分析(TF-IDF) 
    * 单词同现关系分析 
    * 文档倒排索引 
2. 复杂算法或应用 
    * Web搜索 
    * Web访问日志分析 
    * 数据/文本统计分析 
    * 图算法 
    * 聚类(clustring) 
    * 相似性比较分析算法 
    * 基于统计的文本处理
* MapReduce排序算法
1. TotalOrderPartitioner: 一个提供全序划分的Partitioner

* MapReduce单词同现分析算法
1. 矩阵元素M[i, j] 代表单词W[i]与单词W[j]在一定范围内同现的次数（一个语句中，一个段落中，一篇文档中，或文本串中一个宽度为M个单词的窗口中，这些都依具体问题而定）
```
1: classMapper 
2:      methodMap(docida, doc d) 
3:          for allterm w ∈doc d do 
4:              for all term u ∈Neighbors(w) do 
5:                  Emit(pair (w, u),count 1) 
1: classReducer 
2:      method Reduce(pair p; counts [c1, c2,…]) 
3:          s ← 0 
4:          for allcount c in counts [c1, c2,…] do 
5:                  s ← s + c //Sum co-occurrence counts 
6:            Emit(pair p, count s)
```
* MapReduce文档倒排索引算法 
1. 
```
import java.io.IOException; 
import java.util.StringTokenizer; 
import org.apache.hadoop.io.Text; 
import org.apache.hadoop.mapreduce.Mapper; 
public class InvertedIndexMapper extends Mapper<Text, Text, Text, Text> { 
    @Override 
    protected void map(Text key, Text value, Context context)  throws IOException, InterruptedException { 
        FileSplitfileSplit = (FileSplit)context.getInputSplit(); 
        String fileName = fileSplit.getPath().getName(); 
        Text word = new Text(); 
        Text fileName_lineOffset = new Text(fileName+”#”+key.toString()); StringTokenizer itr= new StringTokenizer(value.toString()); 
        for(; itr.hasMoreTokens(); ) {      
            word.set(itr.nextToken()); 
            context.write(word, fileName_lineOffset); 
        } 
    } 
}
```
```
import java.io.IOException; 
import java.util.Collections; 
import java.util.Iterator; 
import org.apache.hadoop.io.Text; 
import org.apache.hadoop.mapreduce.Reducer;
public class InvertedIndexReducer extends Reducer<Text, Text, Text, Text> { 
    @Override 
    protected void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException { 
        Iterator<Text> it = values.iterator(); 
        StringBuilder all = new StringBuilder(); 
        if(it.hasNext())  all.append(it.next().toString()); 
        for(; it.hasNext(); ) { 
            all.append(“;"); 
            all.append(it.next().toString()); 
        } 
        context.write(key, new Text(all.toString())); 
    } //最终输出键值对示例：(“fish", “doc1#0; doc1#8;doc2#0;doc2#8 ") 
}
```
2. 带词频属性的文档倒排算法 
```
1: class Mapper 
2:        procedureMap(docid dn, doc d) 
3:              F ← new AssociativeArray 
4:              for allterm t ∈doc d do 
5:                    F{t} ← F{t} + 1 
6:              for allterm t ∈F do 
7:                    Emit(term t, posting <dn, F{t}>) 
1: class Reducer 
2:        procedureReduce(term t, postings [<dn1, f1>, <dn2, f2>…]) 
3:              P ← new List 
4:              for allposting <dn, f> ∈postings [<dn1, f1>, <dn2, f2>…] do 5:                      Append(P, <dn, f>) 
6:               Sort(P) 
7:               Emit(term t; postings P)
```
3. 改进使得reduce中不需要sort，自定义partitioner

* 专利文献数据分析
```
Citation data set “cite75_99.txt” 
“CITING”,”CITED” 
3858241,956203 
3858241,1324234    
3858241,3398406    
3858241,3557384 
3858241,3634889 
3858242,1515701 
3858242,3319261 
3858242,3668705 
3858242,3707004 
```

```
public static class MapClass extends Mapper<LongWritable, Text, Text, Text> { 
    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException // 输入key: 行偏移值；value: “citing专利号, cited专利号” 数据对 { 
        String[] citation = value.toString().split(“,”); 
        context.write(new Text(citation[1]), new Text(citation[0])); 
    } // 输出key: cited 专利号；value: citing专利号 
}

public static class ReduceClass extends Reducer<Text, Text, Text, Text> { 
    public void reduce(Text key, Iterable<Text> values, Context context) throws IOException, InterruptedException { 
        String csv = “”; 
        for (Text val:values) {    
            if (csv.length() > 0) csv += “,”; 
            csv += val.toString(); 
        } context.write(key, new Text(csv)); 
    } // 输出key: cited专利号；value: “citing专利号1, citing专利号2,…” 
}
